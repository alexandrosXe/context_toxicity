{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBgOfWNze0W+zCE2Sot3LN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrosXe/context_toxicity/blob/master/Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQrllRh18Vlm",
        "colab_type": "text"
      },
      "source": [
        "## **Bert Model for Toxicity Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmo-XY2oVdYT",
        "colab_type": "text"
      },
      "source": [
        "# Install pkbar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqstP7s7Vdzi",
        "colab_type": "code",
        "outputId": "2e8cd8fe-4173-4752-8e19-ed0f94929804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pkbar"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pkbar in /usr/local/lib/python3.6/dist-packages (0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QecwaRs8cgD",
        "colab_type": "text"
      },
      "source": [
        "# Setup. Download the  Transformers library by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf1U1mTy_bCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1G2audg9IAE",
        "colab_type": "code",
        "outputId": "b2b4728b-6492-4e42-e16e-3f1c84db0a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pkbar\n",
        "from sklearn.metrics import *\n",
        "import torch.autograd\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTUZJixq1FhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "#tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0gGXIYMdbci",
        "colab_type": "text"
      },
      "source": [
        "# Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nTcAuzgdd1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "  def __init__(self, patience=7, verbose=False, delta=0):\n",
        "    self.patience = patience\n",
        "    self.verbose = verbose\n",
        "    self.counter = 0\n",
        "    self.best_score = None\n",
        "    self.early_stop = False\n",
        "    self.val_loss_min = np.Inf\n",
        "    self.delta = delta\n",
        "\n",
        "  def __call__(self, val_loss, model):\n",
        "\n",
        "    score = val_loss\n",
        "\n",
        "    if self.best_score is None:\n",
        "      self.best_score = score\n",
        "      self.save_checkpoint(val_loss, model)\n",
        "    elif score <= self.best_score + self.delta:\n",
        "      self.counter += 1\n",
        "      print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "      if self.counter >= self.patience:\n",
        "        self.early_stop = True\n",
        "    else:\n",
        "      self.best_score = score\n",
        "      self.save_checkpoint(val_loss, model)\n",
        "      self.counter = 0\n",
        "\n",
        "  def save_checkpoint(self, val_loss, model):\n",
        "    if self.verbose:\n",
        "      print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "      torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "      self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP5ayBd1Mxlq",
        "colab_type": "text"
      },
      "source": [
        "# Create a PyTorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BxsaiuxMyrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Toxic_Detection_Dataset(Dataset):\n",
        "  def __init__(self, comments, targets, tokenizer, max_len):\n",
        "    self.comments = comments\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comments)\n",
        "\n",
        "    \n",
        "  def __getitem__(self, item):\n",
        "    comment = str(self.comments[item])\n",
        "    target = self.targets[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      comment,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {\n",
        "      'comment_text': comment,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4D6_kmNHqsx",
        "colab_type": "text"
      },
      "source": [
        "# **Bert MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG_intA0D4xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT_MLP(nn.Module):\n",
        "  def __init__(self,\n",
        "                 trainable_layers=3,\n",
        "                 max_seq_length=128,\n",
        "                 show_summary=False,\n",
        "                 label_list=[0, 1],\n",
        "                 patience=3,\n",
        "                 seed=42,\n",
        "                 epochs=100,\n",
        "                 save_predictions=False,\n",
        "                 batch_size=32,\n",
        "                 DATA_COLUMN=\"text\",\n",
        "                 LABEL_COLUMN=\"label\",\n",
        "                 DATA2_COLUMN=None,\n",
        "                 lr=2e-05,\n",
        "                 session=None,\n",
        "                 loss=nn.BCELoss()\n",
        "                 ):\n",
        "    super(BERT_MLP, self).__init__()\n",
        "    self.name = f'{\"OOC1\" if not DATA2_COLUMN else \"OOC2\"}-b{batch_size}.e{epochs}.len{max_seq_length}.bert'\n",
        "    self.tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.lr = lr\n",
        "    self.batch_size = batch_size\n",
        "    self.DATA_COLUMN=DATA_COLUMN\n",
        "    self.DATA2_COLUMN=DATA2_COLUMN\n",
        "    self.LABEL_COLUMN=LABEL_COLUMN\n",
        "    self.trainable_layers = trainable_layers\n",
        "    self.max_seq_length = max_seq_length\n",
        "    self.show_summary = show_summary\n",
        "    self.label_list = label_list\n",
        "    self.patience=patience\n",
        "    self.save_predictions = save_predictions\n",
        "    self.epochs = epochs\n",
        "    self.loss = loss\n",
        "\n",
        "    #Layers\n",
        "    self.bert = BertModel.from_pretrained('bert-base-cased') # (PRE_TRAINED_MODEL_NAME)\n",
        "    self.dense = nn.Linear(self.bert.config.hidden_size,128)\n",
        "    self.denseBn = nn.BatchNorm1d(128)\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.output = nn.Linear(128,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    #if possible run in GPU else in CPU\n",
        "    if torch.cuda.is_available():\n",
        "      self.device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "      print(\"Running on the GPU\")\n",
        "    else:\n",
        "      self.device = torch.device(\"cpu\")\n",
        "      print(\"Running on the CPU\")\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # Get output from bert decoder \n",
        "    cont_reps, pooled_output = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    cls_rep = cont_reps[:, 0]\n",
        "    # feed it to dense NN \n",
        "    output = self.dense(cls_rep)\n",
        "    #output = self.dense(pooled_output)\n",
        "    output=self.densebn(output)\n",
        "    output = self.tanh(output)\n",
        "    output = self.output(output)\n",
        "    output = self.sigmoid(output)\n",
        "    #print(output.squeeze().shape,\"PRINTTT\")\n",
        "    #print(output)\n",
        "    return output.squeeze()\n",
        "\n",
        "  def fit(self, train, val,optimizer,bert_weights=None): #pretrained_embeddings\n",
        "    #Counter class imbalance by setting output layer bias to log(T/N)\n",
        "    pos = sum(train.label)\n",
        "    neg = len(train.label)-pos\n",
        "    bias = np.log(pos/neg)\n",
        "    print (\"BIAS:\", bias)\n",
        "    bias=torch.tensor(bias)\n",
        "    with torch.no_grad():\n",
        "      self.output.bias=torch.nn.Parameter(bias.to(torch.float)) # set bias of last dense layer log(T/N)\n",
        "    self.output.bias.requires_grad_(False)\n",
        "    early_stopping = EarlyStopping(patience=self.patience, verbose=True)     #EARLYY STOPING\n",
        "    self.to(self.device)\n",
        "    i=1 #for progress bar\n",
        "    for epoch in range(self.epochs):\n",
        "      print('\\nEpoch: %d/%d' % (epoch + 1, self.epochs))\n",
        "      kbar = pkbar.Kbar(target=self.epochs, width=10)\n",
        "      kbar_val=pkbar.Kbar(target=self.epochs, width=10)\n",
        "      epoch_loss,epoch_Auc,epoch_accuracy=self.trainin(train,optimizer)\n",
        "      kbar.update(i, values=[(\"loss\",epoch_loss), (\"accuracy\",epoch_accuracy),(\"AUC_score\",epoch_Auc)])  #(\"precision\",epoch_precision),(\"recall\",epoch_recall),(\"F1\",epoch_F1)])\n",
        "      # val_loss,val_AUC_score,val_accuracy,val_recall,val_precision,val_F1=self.evaluate(val)\n",
        "      val_loss,val_AUC_score,val_accuracy=self.evaluate(val)\n",
        "      print(\"\\n Val auc score in epoch \",epoch+1, \":\",val_AUC_score)\n",
        "      early_stopping(val_AUC_score,self)   \n",
        "      if early_stopping.early_stop: #check for early stopping\n",
        "        print(\"Early stopping\")\n",
        "        print(\"_________________________________________________-\")\n",
        "        break\n",
        "      kbar_val.update(i,values=[(\"val_loss\",val_loss), (\"val_accuracy\",val_accuracy),(\"val_AUC_score\",val_AUC_score)])#,(\"val_precision\",val_precision),(\"val_recall\",val_recall),(\"val_F1\",val_F1)])\n",
        "      i+=1\n",
        "\n",
        "  def trainin(self,train,optimizer):\n",
        "    #Create Data Loader for mini batch Training\n",
        "    train_ds = Toxic_Detection_Dataset(comments=train.text.to_numpy(),targets=train.label.to_numpy(),tokenizer=self.tokenizer,max_len=self.max_seq_length)\n",
        "    train_dl=DataLoader(train_ds,batch_size=self.batch_size,shuffle=True)\n",
        "    epoch_loss=0\n",
        "    correct_predictions=0\n",
        "    Y=torch.empty(0) #create empty torch to append predictions\n",
        "    self.train()\n",
        "    for d in train_dl:\n",
        "      #Get Bert inputs \n",
        "      input_ids = d[\"input_ids\"].to(self.device)\n",
        "      attention_mask = d[\"attention_mask\"].to(self.device)\n",
        "      targets = d[\"targets\"].to(self.device)\n",
        "      outputs = self(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      loss = self.loss(outputs, targets.to(torch.float))\n",
        "      epoch_loss+=loss.item()\n",
        "      #losses.append(loss.item())\n",
        "      Y=torch.cat((Y,outputs.cpu()),0)\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "    with torch.no_grad():\n",
        "      predictions=Y\n",
        "      rounded=torch.round(predictions).cpu().detach().numpy()\n",
        "      predictions=predictions.cpu().detach().numpy()\n",
        "      epoch_Auc=roc_auc_score(train.label.to_numpy(),predictions)\n",
        "      epoch_Accuracy=accuracy_score(train.label.to_numpy(),rounded)\n",
        "    return epoch_loss,epoch_Auc,epoch_Accuracy\n",
        "  \n",
        "  #Validation\n",
        "  def evaluate(self,val):\n",
        "    val_ds = Toxic_Detection_Dataset(comments=val.text.to_numpy(),targets=val.label.to_numpy(),tokenizer=self.tokenizer,max_len=self.max_seq_length)\n",
        "    val_dl=DataLoader(val_ds,batch_size=self.batch_size,shuffle=True)\n",
        "    val_loss=0\n",
        "    correct_predictions=0\n",
        "    Y=torch.empty(0) #create empty torch to append predictions\n",
        "    self.eval()\n",
        "    with torch.no_grad():   # compute validation loss\n",
        "      for d in val_dl:\n",
        "        input_ids = d[\"input_ids\"].to(self.device)\n",
        "        attention_mask = d[\"attention_mask\"].to(self.device)\n",
        "        targets = d[\"targets\"].to(self.device)\n",
        "        outputs = self(input_ids=input_ids,attention_mask=attention_mask)\n",
        "        Y=torch.cat((Y,outputs.cpu()),0)\n",
        "        loss = self.loss(outputs, targets.to(torch.float))\n",
        "        val_loss+=loss.item()\n",
        "    predictions=Y\n",
        "    rounded=torch.round(predictions).cpu().detach().numpy()\n",
        "    predictions=predictions.cpu().detach().numpy()\n",
        "    val_Auc=roc_auc_score(val.label.to_numpy(),predictions)\n",
        "    val_Accuracy=accuracy_score(val.label.to_numpy(),rounded)\n",
        "    return val_loss,val_Auc,val_Accuracy\n",
        "\n",
        "  #predict on test data\n",
        "  def predict(self,test):\n",
        "    test_ds = Toxic_Detection_Dataset(comments=test.text.to_numpy(),targets=test.label.to_numpy(),tokenizer=self.tokenizer,max_len=self.max_seq_length)\n",
        "    test_dl=DataLoader(test_ds,batch_size=self.batch_size,shuffle=True)\n",
        "    Y=torch.empty(0) #create empty torch to append predictions\n",
        "    self.eval()\n",
        "    with torch.no_grad():   # compute validation loss\n",
        "      for d in test_dl:\n",
        "        input_ids = d[\"input_ids\"].to(self.device)\n",
        "        attention_mask = d[\"attention_mask\"].to(self.device)\n",
        "        targets = d[\"targets\"].to(self.device)\n",
        "        outputs = self(input_ids=input_ids,attention_mask=attention_mask)\n",
        "        Y=torch.cat((Y,outputs.cpu()),0)\n",
        "    predictions=Y\n",
        "    return predictions \n",
        "\n",
        "  def Unfreeze_Last_K_Layers(self,k=3):\n",
        "    ct = 0\n",
        "    #Bert layers\n",
        "    for child in self.bert.children():\n",
        "      ct += 1\n",
        "      if (ct <= (12-k)):\n",
        "        #Bert's layer's parameters\n",
        "        for param in child.parameters():\n",
        "          param.requires_grad = False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvO8rcOGaowK",
        "colab_type": "text"
      },
      "source": [
        "#Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzgebU4eav79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataN=pd.read_csv(\"dataset/oc.csv\",header=0)\n",
        "dataC=pd.read_csv(\"dataset/wc.csv\",header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCI2rfXoujOK",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIDjXKWYbHrk",
        "colab_type": "text"
      },
      "source": [
        "# 5-fold MC Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7xCQnEJbOHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MC_Validation(dataset,k=5):\n",
        "  avgscore=0\n",
        "  for i in range(k):\n",
        "    model= BERT_MLP(epochs=20)\n",
        "    #model=LSTM_IC1_CLF(vocab_size=size,n_epochs=10)\n",
        "    optimizer=optim.Adam(model.parameters(), lr=model.lr)\n",
        "\n",
        "    # train @N models\n",
        "    X_train, X_test = train_test_split(dataset, test_size=0.4,random_state=i)\n",
        "    #X_train, X_val = train_test_split(X_train,test_size=0.25,random_state=i) # 0.25 x 0.8 = 0.2\n",
        "    XC_train,X_test=train_test_split(dataC, test_size=0.2,random_state=i) # test dataset with C to train and test\n",
        "    XC_train,X_val= train_test_split(XC_train,test_size=0.25,random_state=i) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "    # train @C models\n",
        "    # X_train, X_test = train_test_split(dataset, test_size=0.4,random_state=i)\n",
        "    # #X_train, X_val = train_test_split(X_train,test_size=0.25,random_state=i) # 0.25 x 0.8 = 0.2\n",
        "    # X_val,X_test=train_test_split(X_test, test_size=0.5,random_state=i) # test dataset with C to train and test\n",
        "\n",
        "    # Perform MC Validation\n",
        "    model.fit(X_train,X_val,optimizer)  #bert_weights=\"bert_weights.h5\"\n",
        "    preds=model.predict(X_test)#X_test.text.to_numpy())\n",
        "    preds=preds.cpu().detach().numpy()\n",
        "    gold=X_test.label\n",
        "    print(\"\\n__________________________________\\n\") \n",
        "    score = roc_auc_score(gold, preds)\n",
        "    print(\"AUC score in \",i+1,\" fold \",score)\n",
        "    print(\"\\n__________________________________\") #to see results\n",
        "    avgscore+=score\n",
        "  avgscore/=k\n",
        "  return avgscore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ziYIxKSbryH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Average AUC score over 5fold MC validation is \",MC_Validation(dataset=dataN,k=5)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfW-tJl8_7AI",
        "colab_type": "text"
      },
      "source": [
        "# Stratified MC validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu5_UnLx_7sc",
        "colab_type": "code",
        "outputId": "f9073ce0-42e5-4a4d-92ba-0b4e68d385df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#Make stratified split in @N dataset for train data\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.4, random_state=0)\n",
        "X=dataN.text.to_numpy()\n",
        "y=dataN.label.to_numpy()\n",
        "train=list(sss.split(X,y))\n",
        "\n",
        "#Make stratified split in @C dataset for val and test data\n",
        "sss_Val = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=3)\n",
        "X_val=dataC.text.to_numpy()\n",
        "y_val=dataC.label.to_numpy()\n",
        "val_and_test=list(sss_Val.split(X_val,y_val))\n",
        "train_index,test_index = val_and_test[0]\n",
        "X_train, X_val_test = X_val[train_index], X_val[test_index]\n",
        "y_train, y_val_test = y_val[train_index], y_val[test_index]\n",
        "\n",
        "# Now make stratified split in 40% of C dataset for val(20%) and test(20%)\n",
        "sss_Val= StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
        "val_and_test=list( sss_Val.split(X_val_test,y_val_test))\n",
        "avgscore=0\n",
        "for i in range(5):\n",
        "  train_index, _ = train[i]\n",
        "  val_index , test_index = val_and_test[i]\n",
        "  X_train,y_train=X[train_index],y[train_index]\n",
        "  X_val,y_val=X_val_test[val_index],y_val_test[val_index]\n",
        "  X_test,y_test=X_val_test[test_index],y_val_test[test_index]\n",
        "  \n",
        "  # Create X_train , X_val and X_test Dataframes\n",
        "  X_train=pd.DataFrame({'text': X_train,'label': y_train})\n",
        "  X_val=pd.DataFrame({'text': X_val,'label': y_val})\n",
        "  X_test=pd.DataFrame({'text': X_test,'label': y_test})\n",
        "  #print(X_train.loc[X_train['label']==1].shape)\n",
        "  # print(X_val.shape)\n",
        "  # print(X_test.shape)\n",
        "  model= BERT_MLP(epochs=20)\n",
        "  #model.Unfreeze_Last_K_Layers(k=3)\n",
        "  optimizer=optim.Adam(model.parameters(), lr=model.lr)\n",
        "  model.fit(X_train,X_val,optimizer)  #bert_weights=\"bert_weights.h5\"\n",
        "  preds=model.predict(X_test)\n",
        "  preds=preds.cpu().detach().numpy()\n",
        "  gold=X_test.label.to_numpy()\n",
        "  print(\"\\n__________________________________\\n\") \n",
        "  score = roc_auc_score(gold, preds)\n",
        "  print(\"AUC score in \",i+1,\" fold \",score)\n",
        "  print(\"\\n__________________________________\") #to see results\n",
        "  avgscore+=score\n",
        "result=avgscore/5\n",
        "print(\"Average AUC score over 5fold MC validation is \",result) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n",
            "BIAS: -5.138316273042602\n",
            "\n",
            "Epoch: 1/20\n",
            " 1/20 [..........] - ETA: 1:15:11 - loss: 6.8360 - accuracy: 0.9942 - AUC_score: 0.5279\n",
            " Val auc score in epoch  1 : 0.5251607445008459\n",
            "Validation loss decreased (inf --> 0.525161).  Saving model ...\n",
            " 1/20 [..........] - ETA: 1:24:43 - val_loss: 4.7713 - val_accuracy: 0.9850 - val_AUC_score: 0.5252\n",
            "Epoch: 2/20\n",
            " 2/20 [>.........] - ETA: 35:33 - loss: 5.0973 - accuracy: 0.9942 - AUC_score: 0.5187\n",
            " Val auc score in epoch  2 : 0.3755583756345178\n",
            "EarlyStopping counter: 1 out of 3\n",
            " 2/20 [>.........] - ETA: 39:54 - val_loss: 5.2278 - val_accuracy: 0.9850 - val_AUC_score: 0.3756\n",
            "Epoch: 3/20\n",
            " 3/20 [>.........] - ETA: 22:22 - loss: 3.3532 - accuracy: 0.9942 - AUC_score: 0.4879\n",
            " Val auc score in epoch  3 : 0.4977664974619289\n",
            "EarlyStopping counter: 2 out of 3\n",
            " 3/20 [>.........] - ETA: 25:07 - val_loss: 4.9565 - val_accuracy: 0.9845 - val_AUC_score: 0.4978\n",
            "Epoch: 4/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mBj7DpeLCAy",
        "colab_type": "code",
        "outputId": "70dd6eb9-81db-451f-af2f-612b66265984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Get toxic comments and give them always to train set\n",
        "toxics=dataN.loc[dataN['label']==1]\n",
        "Non_toxics=dataN[dataN.label != 1]\n",
        "Non_toxics=dataN[0:59]\n",
        "#print(Non_toxics.shape)\n",
        "# Non_toxics=dataN.loc[dataN['label']==0]\n",
        "# Non_toxics=Non_toxics[0:100]\n",
        "# #print(Non_toxics.label.head(100))\n",
        "frames = [toxics,Non_toxics]\n",
        "data = pd.concat(frames)\n",
        "print(data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(118, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYiv8inSLauE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avgscore=0\n",
        "for i in range(5):\n",
        "  model=BERT_MLP(epochs=20)\n",
        "  model.Unfreeze_Last_K_Layers(k=3)\n",
        "  optimizer=optim.Adam(model.parameters(), lr=model.lr)\n",
        "  X_train, X_val = train_test_split(data, test_size=0.2,random_state=i)\n",
        "  model.fit(data,X_val,optimizer)  #bert_weights=\"bert_weights.h5\"\n",
        "  preds=model.predict(data)\n",
        "  preds=preds.cpu().detach().numpy()\n",
        "  #preds=torch.round(preds).cpu().detach().numpy()\n",
        "  gold=data.label.to_numpy()\n",
        "  print(\"\\n__________________________________\\n\") \n",
        "  score = roc_auc_score(gold, preds)\n",
        "  print(\"AUC score in \",i+1,\" fold \",score)\n",
        "  print(\"\\n__________________________________\") #to see results\n",
        "  avgscore+=score\n",
        "result=avgscore/5\n",
        "print(\"Average AUC score over 5fold MC validation is \",result) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}